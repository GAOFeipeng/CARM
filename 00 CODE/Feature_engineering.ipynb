{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "codeN = 3\n",
    "Limit = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFile(p):\n",
    "    listdir = os.listdir(p)\n",
    "\n",
    "    # 遍历文件名数组，拼接路径\n",
    "    f = []\n",
    "    for i in range(len(listdir)):\n",
    "        s = p + listdir[i]\n",
    "\n",
    "        # 读入文件，切片\n",
    "        v = pd.read_table(s, header=None).iloc[:, 21:24].values\n",
    "        f.append(v)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hash_name(rule):\n",
    "    res = \"\"\n",
    "    for r in rule:\n",
    "        res += str(r) + \"-\"\n",
    "    return res[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rule_X(_v, rule):\n",
    "    lenr = len(rule)\n",
    "    mat = dict()\n",
    "   \n",
    "    div_l = np.array(rule) // codeN\n",
    "    mod_l = np.array(rule) % codeN\n",
    "    len_frame = max(div_l) # this is windows size.\n",
    "    val = np.zeros(lenr,dtype=np.int16)\n",
    "    for v in _v:\n",
    "        # for each speech\n",
    "        lenv = len(v)\n",
    "        for i in range(lenv - len_frame):\n",
    "            # for each frame\n",
    "            for _t in range(lenr):\n",
    "                # get index frame with rule's codeword.\n",
    "                # get index frame sub.\n",
    "                val[_t] = v[i + div_l[_t]][mod_l[_t]]\n",
    "                # get codeword with index.\n",
    "            tp = tuple(val)\n",
    "            if tp in mat:\n",
    "                mat[tp] += 1\n",
    "            else:\n",
    "                mat[tp] = 1\n",
    "            \n",
    "            # calc confidence of rule, this PAR.\n",
    "            tp_par = tp[:-1]\n",
    "            if tp_par in mat:\n",
    "                mat[tp_par] += 1\n",
    "            else:\n",
    "                mat[tp_par] = 1\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rules(v, rules):\n",
    "    # train dataset v with rules.\n",
    "    resMat = dict()\n",
    "    cnt = 0\n",
    "    for rule in rules:\n",
    "        mat = train_rule_X(v, rule)\n",
    "        hash_name = get_hash_name(rule)\n",
    "        resMat[hash_name] = mat\n",
    "        print('\\r', cnt , \"/\" , len(rules), end=\"\")\n",
    "        cnt += 1\n",
    "    print('\\r', end=\"\")\n",
    "    return resMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rules_2():\n",
    "    rules = []\n",
    "    for i in range(codeN):\n",
    "        for j in range(i + 1, codeN):\n",
    "            rules.append([i, j])\n",
    "    # 帧内1->1\n",
    "    for i in range(codeN):\n",
    "        for j in range(codeN):\n",
    "            rules.append([i, j + codeN])\n",
    "    return rules\n",
    "    # 帧间1->1\n",
    "def get_rules_3():\n",
    "    rules = []\n",
    "    rules.append([0, 1, 2])\n",
    "    # 帧内1->2 (帧内2->1)\n",
    "    for i in range(codeN):\n",
    "        for j in range(codeN):\n",
    "            for k in range(j + 1, codeN):\n",
    "                rules.append([i, j + codeN, k + codeN])\n",
    "    # 帧间1->2\n",
    "    \n",
    "    for i in range(codeN):\n",
    "        for j in range(i + 1, codeN):\n",
    "            for k in range(codeN):\n",
    "                rules.append([i, j, k + codeN])\n",
    "    # 帧间2->1\n",
    "    return rules\n",
    "\n",
    "def get_rules_2_and_3():\n",
    "    return get_rules_2() + get_rules_3()\n",
    "\n",
    "\n",
    "def get_index_from_rule(rule):\n",
    "    if len(rule) == 2:\n",
    "        # 帧内或帧间1->1\n",
    "        if rule[1] < codeN: return 0 # 帧内1->1\n",
    "        else : return 1 # 帧间1->1\n",
    "    elif len(rule) == 3:\n",
    "        if rule[2] < codeN: return 2 # 帧内1->2\n",
    "        if rule[1] >= codeN: return 3 # 帧间1->2\n",
    "        else: return 4 # 帧间2->1\n",
    "        \n",
    "# 从规则反解下标\n",
    "\n",
    "def get_name_from_index(index):\n",
    "    name_list = ['帧内1->1', '帧间1->1',\n",
    "                 '帧内1->2','帧间1->2', '帧间2->1']\n",
    "    return name_list[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_rule_X(_v, rule, MC, MS):\n",
    "    lenr = len(rule)\n",
    "    hash_name = get_hash_name(rule)\n",
    "    f = np.zeros((len(_v), 2), dtype=np.int32)\n",
    "    div_l = np.array(rule) // codeN\n",
    "    mod_l = np.array(rule) % codeN\n",
    "    len_frame = max(div_l) # this is windows size. T >= 1 is inter, T = 0 is intra.\n",
    "    val = np.zeros(lenr, dtype=np.int16)\n",
    "    for p in range(len(_v)):\n",
    "        v = _v[p]\n",
    "        # for each speech\n",
    "        lenv = len(v)\n",
    "        a = 0\n",
    "        b = 0\n",
    "        for i in range(lenv - len_frame):\n",
    "            # for each frame\n",
    "            for _t in range(lenr):\n",
    "                # index_frame = i + div_l[_t]\n",
    "                # index_frame_sub = mod_l[_t]\n",
    "                # get index frame sub.\n",
    "                val[_t] = v[i + div_l[_t]][mod_l[_t]]\n",
    "            tp = tuple(val)\n",
    "            \n",
    "            t1 = tp in MC[hash_name]\n",
    "            t2 = tp in MS[hash_name]\n",
    "            if t1 and not t2: a += 1\n",
    "            elif not t1 and t2: b += 1\n",
    "        f[p][0] += a\n",
    "        f[p][1] += b\n",
    "    return f\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_rules(_v, rules, MC, MS):\n",
    "    fea = np.zeros((len(_v), 5, 2))\n",
    "    cnt = 0\n",
    "    for rule in rules:\n",
    "        hash_index = get_index_from_rule(rule)\n",
    "        f = test_rule_X(_v, rule, MC, MS)\n",
    "        for i in range(len(f)):\n",
    "            for j in range(2):\n",
    "                fea[i][hash_index][j] += f[i][j]\n",
    "        print('\\r', cnt , \"/\" , len(rules), end=\"\")\n",
    "        cnt += 1\n",
    "    print('\\r', end=\"\")\n",
    "    return fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveFeaWithCsv(fc, fs, name):\n",
    "    res = []\n",
    "    for i in range(len(fc)):\n",
    "        fea_cover_line = np.append(fc[i].reshape(1, -1), 0)\n",
    "        res.append(fea_cover_line)\n",
    "    for i in range(len(fs)):\n",
    "        fea_stego_line = np.append(fs[i].reshape(1, -1), 1)\n",
    "        res.append(fea_stego_line)\n",
    "        \n",
    "    pd.DataFrame(res).to_csv(name, header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_v(v, split_len):\n",
    "    res = []\n",
    "    for _v in v:\n",
    "        _x = _v[:split_len]\n",
    "        res.append(_x)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30 / 31\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "904.6901962757111"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vc_train = split_v(getFile(\"h:\\\\dataset\\\\CNV_divide\\\\0.0\\\\Chinese\\\\train\\\\\"), 333)\n",
    "Vc_valid = split_v(getFile(\"h:\\\\dataset\\\\CNV_divide\\\\0.0\\\\Chinese\\\\valid\\\\\"), 333)\n",
    "Vc_test = split_v(getFile(\"h:\\\\dataset\\\\CNV_divide\\\\0.0\\\\Chinese\\\\test\\\\\"), 333)\n",
    "startTime = time.time()\n",
    "matOfCover = None\n",
    "matOfStego = None\n",
    "matOfCover = train_rules(Vc_train, get_rules_2_and_3())\n",
    "time.time() - startTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 11):\n",
    "    StartTime = time.time()\n",
    "    rate_text = \"1.0\"\n",
    "    if i < 10:\n",
    "        rate_text = \"0.\" + str(i)\n",
    "    \n",
    "    Vs_train = split_v(getFile(\"h:\\\\dataset\\\\CNV_divide\\\\\" + rate_text + \"\\\\Chinese\\\\train\\\\\"), 333)\n",
    "    Vs_valid = split_v(getFile(\"h:\\\\dataset\\\\CNV_divide\\\\\" + rate_text + \"\\\\Chinese\\\\train\\\\\"), 333)\n",
    "    Vs_test = split_v(getFile(\"h:\\\\dataset\\\\CNV_divide\\\\\" + rate_text + \"\\\\Chinese\\\\test\\\\\"), 333)\n",
    "    # read stego files.\n",
    "    \n",
    "    matOfStego = None\n",
    "    matOfStego = train_rules(Vs_train, get_rules_all())\n",
    "    print(\"train over.\", int(time.time() - StartTime),\"sec\")\n",
    "    # train samples.\n",
    "    \n",
    "    f_vc = test_rules(Vc_valid, get_rules_all(), matOfCover, matOfStego)\n",
    "    print(\"get valid feature with cover over.\", int(time.time() - StartTime),\"sec\")\n",
    "    f_vs = test_rules(Vs_valid, get_rules_all(), matOfCover, matOfStego)\n",
    "    print(\"get valid feature with stego over.\", int(time.time() - StartTime),\"sec\")\n",
    "    # get featrue with rules from MAT.\n",
    "    saveFeaWithCsv(f_vc, f_vs, \"../01 DATA/CNV/CH_VALID_RATE_ALL_\" + str(i) + \".csv\")\n",
    "\n",
    "    f_tc = test_rules(Vc_test, get_rules_all(), matOfCover, matOfStego)\n",
    "    print(\"get test feature with cover over.\", int(time.time() - StartTime),\"sec\")\n",
    "    f_ts = test_rules(Vs_test, get_rules_all(), matOfCover, matOfStego)\n",
    "    print(\"get test feature with stego over.\", int(time.time() - StartTime),\"sec\")\n",
    "    saveFeaWithCsv(f_tc, f_ts, \"../01 DATA/CNV/CH_TEST_RATE_ALL_\" + str(i) + \".csv\")\n",
    "\n",
    "    # non auto rate(rate = 1)\n",
    "    print(\"cast time=\", int(time.time() - StartTime),\"sec\", \"with CH in time(s)=\", i)\n",
    "    print(time.localtime())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 短时长与极短时长的准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vc_train_p = getFile(\"h:\\\\dataset\\\\CNV_divide\\\\0.0\\\\Chinese\\\\train\\\\\")\n",
    "Vc_valid_p = getFile(\"h:\\\\dataset\\\\CNV_divide\\\\0.0\\\\Chinese\\\\valid\\\\\")\n",
    "Vc_test_p = getFile(\"h:\\\\dataset\\\\CNV_divide\\\\0.0\\\\Chinese\\\\test\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 11):\n",
    "    StartTime = time.time()\n",
    "    length_text = \"1.0\"\n",
    "    if i < 10:\n",
    "        length_text = \"0.\" + str(i)\n",
    "    \n",
    "    Vs_train_p = getFile(\"h:\\\\dataset\\\\CNV_divide\\\\\" + length_text + \"\\\\Chinese\\\\train\\\\\")\n",
    "    Vs_valid_p = getFile(\"h:\\\\dataset\\\\CNV_divide\\\\\" + length_text + \"\\\\Chinese\\\\valid\\\\\")\n",
    "    Vs_test_p = getFile(\"h:\\\\dataset\\\\CNV_divide\\\\\" + length_text + \"\\\\Chinese\\\\test\\\\\")\n",
    "    SPEECH_LEN = int(i * 100 / 3) # 10 / 3表示每个0.1s时长，100 / 3表示每个1s时长\n",
    "    \n",
    "    Vc_train = split_v(Vc_train_p, SPEECH_LEN)\n",
    "    Vc_valid = split_v(Vc_valid_p, SPEECH_LEN)\n",
    "    Vc_test = split_v(Vc_test_p, SPEECH_LEN)\n",
    "    \n",
    "    Vs_train = split_v(Vs_train_p, SPEECH_LEN)\n",
    "    Vs_valid = split_v(Vs_valid_p, SPEECH_LEN)\n",
    "    Vs_test = split_v(Vs_test_p, SPEECH_LEN)\n",
    "    # read stego files.\n",
    "    matOfCover = None\n",
    "    matOfStego = None\n",
    "    \n",
    "    matOfCover = train_rules(Vc_train, get_rules_all())\n",
    "    matOfStego = train_rules(Vs_train, get_rules_all())\n",
    "    print(\"train over.\")\n",
    "    # train samples.\n",
    "    \n",
    "    f_vc = test_rules(Vc_valid, get_rules_all(), matOfCover, matOfStego)\n",
    "    print(\"get valid feature with cover over.\")\n",
    "\n",
    "    f_vs = test_rules(Vs_valid, get_rules_all(), matOfCover, matOfStego)\n",
    "    print(\"get valid feature with stego over.\")\n",
    "    # get featrue with rules from MAT.\n",
    "    saveFeaWithCsv(f_vc, f_vs, \"../01 DATA/CNV/CH_VALID_TIME_ALL_\" + str(i) + \".csv\")\n",
    "    MidTime = time.time();\n",
    "    f_tc = test_rules(Vc_test, get_rules_all(), matOfCover, matOfStego)\n",
    "    print(\"get test feature with cover over.\")\n",
    "    f_ts = test_rules(Vs_test, get_rules_all(), matOfCover, matOfStego)\n",
    "    print(\"get test feature with stego over.\")\n",
    "    saveFeaWithCsv(f_tc, f_ts, \"../01 DATA/CNV/CH_TEST_TIME_ALL_\" + str(i) + \".csv\")\n",
    "    # non auto rate(rate = 1)\n",
    "    print(\"cast time=\", int(time.time() - StartTime),\"sec\", \"with CH in time(s)=\", i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
